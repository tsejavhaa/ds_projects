{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c277f8e",
   "metadata": {},
   "source": [
    "# Fake News Detector using BERT and PyTorch\n",
    "\n",
    "- BERT Based Fake News Detector (HugginFace Transformers, Pytorch)\n",
    "- Fine-tune a pretrained transformers (DistilBERT / BERT) on Fake vs Real news\n",
    "- Evaluate using accuracy / precision / recall / f1\n",
    "- Save Tokenizer + model for inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dddf41e",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a06d75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "from datasets import Dataset, load_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe577616",
   "metadata": {},
   "source": [
    "## Setting hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0c45aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "MODEL_NAME = \"distilbert-base-uncased\"   # use \"bert-base-uncased\" if you have GPU and more time\n",
    "MAX_SAMPLES = None   # e.g., 20000 for subsampling on low-memory machines, or None to use all\n",
    "MAX_LENGTH = 256     # truncation/padding length\n",
    "BATCH_SIZE = 16      # reduce to 8 or 4 on low-memory CPUs\n",
    "EPOCHS = 3\n",
    "OUTPUT_DIR = \"hf_fake_news_model\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2450b095",
   "metadata": {},
   "source": [
    "## Download and Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c01745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "\n",
    "download_path = \"\"\n",
    "os.environ[\"KAGGLEHUB_CACHE\"] = download_path\n",
    "\n",
    "dataset_identifier = \"clmentbisaillon/fake-and-real-news-dataset\"\n",
    "path = kagglehub.dataset_download(dataset_identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d97448",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.getcwd()\n",
    "real_file = \"True.csv\"\n",
    "fake_file = \"Fake.csv\"\n",
    "real_path = \"\"\n",
    "fake_path = \"\"\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    for filename in filenames:\n",
    "        if filename == real_file:\n",
    "            real_path = os.path.join(dirpath, filename)\n",
    "        elif filename == fake_file:\n",
    "            fake_path = os.path.join(dirpath, filename)\n",
    "    \n",
    "fake = pd.read_csv(fake_path)\n",
    "real = pd.read_csv(real_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141b5560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label: fake=0, real=1\n",
    "fake[\"label\"] = 0\n",
    "real[\"label\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec629f8",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f9c026",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([fake, real], axis=0).sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "# Keep only text fields to simplify\n",
    "df[\"content\"] = (df[\"title\"].fillna(\"\") + \" \" + df[\"text\"].fillna(\"\")).str.strip()\n",
    "df = df[[\"content\", \"label\"]]\n",
    "df = df[df[\"content\"].str.len() > 30].reset_index(drop=True)   # remove extremely short rows\n",
    "\n",
    "# Optional downsample for low memory\n",
    "if isinstance(MAX_SAMPLES, int) and MAX_SAMPLES > 0:\n",
    "    df = df.sample(n=MAX_SAMPLES, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "print(\"Dataset size:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fbf8e0",
   "metadata": {},
   "source": [
    "## Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afcace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(df, test_size=0.15, random_state=SEED, stratify=df[\"label\"])\n",
    "print(\"Train:\", train_df.shape, \"Val:\", val_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcedfb0",
   "metadata": {},
   "source": [
    "## Convert HugginFace Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47288db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Convert to HuggingFace Dataset\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "val_ds = Dataset.from_pandas(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad993cc",
   "metadata": {},
   "source": [
    "## Load Tokenizer and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a1d734",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63150a7",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae6d794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_fn(batch):\n",
    "    return tokenizer(batch[\"content\"], padding=False, truncation=True, max_length=MAX_LENGTH)\n",
    "\n",
    "# Use map to tokenize datasets (batched)\n",
    "train_ds = train_ds.map(tokenize_fn, batched=True, remove_columns=[\"content\"])\n",
    "val_ds = val_ds.map(tokenize_fn, batched=True, remove_columns=[\"content\"])\n",
    "\n",
    "# Data collator (dynamic padding)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e1d152",
   "metadata": {},
   "source": [
    "## Set Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5cb7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_acc = load_metric(\"accuracy\")\n",
    "metric_f1 = load_metric(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n",
    "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c5f111",
   "metadata": {},
   "source": [
    "## Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2a8984",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=100,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    fp16=torch.cuda.is_available(),  # only if GPU supports it\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99d2fe8",
   "metadata": {},
   "source": [
    "## Initialize Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce5481f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1e94be",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b49a66f",
   "metadata": {},
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3a9a5e",
   "metadata": {},
   "source": [
    "## Save Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984d45cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9a6d60",
   "metadata": {},
   "source": [
    "## Eval Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161ff6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_res = trainer.evaluate(eval_dataset=val_ds)\n",
    "print(\"Eval results:\", eval_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acbe465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed classification report on validation set\n",
    "val_preds = trainer.predict(val_ds)\n",
    "val_logits = val_preds.predictions\n",
    "val_labels = val_preds.label_ids\n",
    "val_preds_arg = np.argmax(val_logits, axis=-1)\n",
    "\n",
    "print(\"Classification Report (val):\")\n",
    "print(classification_report(val_labels, val_preds_arg, target_names=[\"FAKE\",\"REAL\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ac68d4",
   "metadata": {},
   "source": [
    "## Example inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae23f9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text-classification\", model=OUTPUT_DIR, tokenizer=OUTPUT_DIR, device=0 if torch.cuda.is_available() else -1)\n",
    "\n",
    "samples = [\n",
    "    \"Local council approves new budget for schools and parks.\",\n",
    "    \"Shocking: cure for common cold discovered by home remedy!\"\n",
    "]\n",
    "print(pipe(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f28b19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "Notes:\n",
    "- For production, set max_length carefully; longer max_length increases memory.\n",
    "- You can switch MODEL_NAME to 'bert-base-uncased' for (usually) better results if you have GPU.\n",
    "- To train on full dataset on CPU, use smaller BATCH_SIZE (4 or 8) and fewer EPOCHS.\n",
    "- Use HuggingFace Accelerate or Deepspeed for multi-GPU / large-scale training.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3983fd0d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
